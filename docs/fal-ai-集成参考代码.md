# ğŸ¬ fal.ai é›†æˆå‚è€ƒä»£ç 

> ä» temp-video-starter-kit é¡¹ç›®ä¸­æå–çš„é‡è¦ä»£ç ï¼Œç”¨äºæœªæ¥é›†æˆ fal.ai è§†é¢‘ç”ŸæˆæœåŠ¡

## ğŸ“‹ **é¡¹ç›®æ¦‚è¿°**

temp-video-starter-kit æ˜¯ä¸€ä¸ªåŸºäº fal.ai çš„è§†é¢‘ç”Ÿæˆé¡¹ç›®ï¼ŒåŒ…å«ä»¥ä¸‹æ ¸å¿ƒåŠŸèƒ½ï¼š
- å¤šç§AIæ¨¡å‹é›†æˆ (Veo2, Minimax, Klingç­‰)
- è§†é¢‘ç¼–è¾‘å’Œåˆæˆ
- Remotion è§†é¢‘æ¸²æŸ“
- IndexedDB æœ¬åœ°å­˜å‚¨

## ğŸ”§ **æ ¸å¿ƒé…ç½®æ–‡ä»¶**

### fal.ai å®¢æˆ·ç«¯é…ç½®
```typescript
// src/lib/fal.ts
"use client";

import { createFalClient } from "@fal-ai/client";

export const fal = createFalClient({
  credentials: () => {
    if (typeof localStorage === "object") {
      return localStorage.getItem("falKey") as string;
    }
    return undefined;
  },
  proxyUrl: "/api/fal",
});

export type ApiInfo = {
  endpointId: string;
  label: string;
  description: string;
  cost: string;
  inferenceTime?: string;
  inputMap?: Record<string, string>;
  inputAsset?: InputAsset[];
  initialInput?: Record<string, unknown>;
  cameraControl?: boolean;
  imageForFrame?: boolean;
  category: "image" | "video" | "music" | "voiceover";
  prompt?: boolean;
  from?: string;
};

export const AVAILABLE_ENDPOINTS: ApiInfo[] = [
  {
    endpointId: "fal-ai/veo2",
    label: "Veo 2",
    description: "Veo creates videos with realistic motion and high quality output, up to 4K.",
    cost: "",
    category: "video",
    from: "Google",
  },
  {
    endpointId: "fal-ai/veo2/image-to-video",
    label: "Veo 2 (Image to Video)",
    description: "Veo 2 creates videos from images with realistic motion and very high quality output.",
    cost: "",
    category: "video",
    inputAsset: ["image"],
    from: "Google",
  },
  {
    endpointId: "fal-ai/minimax/video-01-live",
    label: "Minimax Video 01 Live",
    description: "High quality video, realistic motion and physics",
    cost: "",
    category: "video",
    inputAsset: ["image"],
  },
  // ... æ›´å¤šç«¯ç‚¹é…ç½®
];
```

### è§†é¢‘ç”Ÿæˆæ ¸å¿ƒé€»è¾‘
```typescript
// è§†é¢‘ç”Ÿæˆå‡½æ•°
const generateVideo = async (input: any) => {
  const { data } = await fal.subscribe(endpointId, {
    input: {
      prompt: input.prompt,
      image_url: input.image_url,
      aspect_ratio: input.aspect_ratio,
      seconds_total: input.duration,
    },
    mode: "polling",
    pollInterval: 3000,
  });
  
  return data;
};
```

### åª’ä½“å…ƒæ•°æ®è·å–
```typescript
// src/lib/ffmpeg.ts
export async function getMediaMetadata(media: MediaItem) {
  try {
    const { data: mediaMetadata } = await fal.subscribe(
      "fal-ai/ffmpeg-api/metadata",
      {
        input: {
          media_url: resolveMediaUrl(media),
          extract_frames: true,
        },
        mode: "streaming",
      },
    );

    return mediaMetadata;
  } catch (error) {
    console.error(error);
    return {};
  }
}
```

### è§†é¢‘åˆæˆå’Œå¯¼å‡º
```typescript
// è§†é¢‘å¯¼å‡ºåŠŸèƒ½
const exportVideo = async (tracks: any[]) => {
  const videoData = tracks.map((track) => ({
    id: track.id,
    type: track.type === "video" ? "video" : "audio",
    keyframes: frames[track.id].map((frame) => ({
      timestamp: frame.timestamp,
      duration: frame.duration,
      url: resolveMediaUrl(mediaItems[frame.data.mediaId]),
    })),
  }));

  const { data } = await fal.subscribe("fal-ai/ffmpeg-api/compose", {
    input: {
      tracks: videoData,
    },
    mode: "polling",
    pollInterval: 3000,
  });
  
  return data;
};
```

## ğŸ¨ **Remotion è§†é¢‘ç»„åˆ**

### è§†é¢‘ç»„åˆç»„ä»¶
```typescript
// src/components/video-preview.tsx
const VideoComposition: React.FC<VideoCompositionProps> = ({
  project,
  tracks,
  frames,
  mediaItems,
}) => {
  const sortedTracks = [...tracks].sort((a, b) => {
    return TRACK_TYPE_ORDER[a.type] - TRACK_TYPE_ORDER[b.type];
  });

  let width = VIDEO_WIDTH;
  let height = VIDEO_HEIGHT;

  if (project.aspectRatio) {
    const size = videoSizeMap[project.aspectRatio];
    if (size) {
      width = size.width;
      height = size.height;
    }
  }

  return (
    <Composition
      id={project.id}
      component={MainComposition as any}
      durationInFrames={DEFAULT_DURATION * FPS}
      fps={FPS}
      width={width}
      height={height}
      defaultProps={{
        project,
        tracks: sortedTracks,
        frames,
        mediaItems,
      }}
    />
  );
};
```

## ğŸ“Š **æ•°æ®ç»“æ„å®šä¹‰**

### åª’ä½“é¡¹ç›®ç±»å‹
```typescript
interface MediaItem {
  id: string;
  kind: "generated" | "uploaded";
  input: Record<string, any>;
  mediaType: "image" | "video" | "audio" | "music";
  status: "pending" | "completed" | "failed";
  createdAt: number;
  endpointId: string;
  projectId: string;
  requestId: string;
  output?: {
    video?: {
      url: string;
      content_type: string;
      file_name: string;
      file_size: number;
    };
    images?: Array<{
      url: string;
      width: number;
      height: number;
      content_type: string;
    }>;
    audio_file?: {
      url: string;
      content_type: string;
      file_name: string;
      file_size: number;
    };
  };
  metadata?: {
    media_type: string;
    url: string;
    content_type: string;
    file_name: string;
    file_size: number;
    duration?: number;
    bitrate?: number;
    codec?: string;
    container?: string;
    fps?: number;
    frame_count?: number;
    resolution?: {
      aspect_ratio: string;
      width: number;
      height: number;
    };
  };
}
```

### é¡¹ç›®é…ç½®ç±»å‹
```typescript
interface VideoProject {
  id: string;
  title: string;
  description: string;
  aspectRatio: "16:9" | "9:16" | "1:1";
  createdAt: number;
  updatedAt: number;
}
```

## ğŸ”„ **çŠ¶æ€ç®¡ç†**

### Zustand Store é…ç½®
```typescript
interface VideoProjectStore {
  // ç”Ÿæˆå¯¹è¯æ¡†çŠ¶æ€
  generateDialogOpen: boolean;
  openGenerateDialog: () => void;
  closeGenerateDialog: () => void;
  
  // åª’ä½“é€‰æ‹©
  selectedMediaId: string | null;
  setSelectedMediaId: (id: string | null) => void;
  
  // ç”Ÿæˆæ•°æ®
  generateData: GenerateData;
  setGenerateData: (data: Partial<GenerateData>) => void;
  
  // ç«¯ç‚¹é…ç½®
  endpointId: string;
  setEndpointId: (id: string) => void;
  
  // åª’ä½“ç±»å‹
  generateMediaType: "image" | "video" | "music" | "voiceover";
  setGenerateMediaType: (type: "image" | "video" | "music" | "voiceover") => void;
}
```

## ğŸ¯ **é›†æˆå»ºè®®**

### 1. æ¸è¿›å¼é›†æˆ
```typescript
// ç¬¬ä¸€æ­¥ï¼šé›†æˆåŸºç¡€çš„fal.aiå®¢æˆ·ç«¯
// ç¬¬äºŒæ­¥ï¼šæ·»åŠ è§†é¢‘ç”Ÿæˆç«¯ç‚¹
// ç¬¬ä¸‰æ­¥ï¼šé›†æˆRemotionè§†é¢‘åˆæˆ
// ç¬¬å››æ­¥ï¼šæ·»åŠ é«˜çº§ç¼–è¾‘åŠŸèƒ½
```

### 2. ç¯å¢ƒå˜é‡é…ç½®
```bash
# fal.ai é…ç½®
FAL_KEY=your_fal_api_key

# ä»£ç†é…ç½® (å¯é€‰)
FAL_PROXY_URL=/api/fal
```

### 3. ä¾èµ–åŒ…å®‰è£…
```json
{
  "dependencies": {
    "@fal-ai/client": "^0.7.3",
    "@remotion/cli": "^4.0.0",
    "@remotion/player": "^4.0.0",
    "zustand": "^4.4.0"
  }
}
```

## ğŸ“ **å®æ–½æ­¥éª¤**

1. **å®‰è£…ä¾èµ–**: æ·»åŠ  fal.ai å®¢æˆ·ç«¯å’Œç›¸å…³ä¾èµ–
2. **é…ç½®å®¢æˆ·ç«¯**: è®¾ç½® API å¯†é’¥å’Œä»£ç†
3. **é›†æˆç«¯ç‚¹**: æ·»åŠ è§†é¢‘ç”Ÿæˆç«¯ç‚¹é…ç½®
4. **å®ç°ç”Ÿæˆ**: åˆ›å»ºè§†é¢‘ç”Ÿæˆå‡½æ•°
5. **æ·»åŠ UI**: é›†æˆç”Ÿæˆç•Œé¢å’Œè¿›åº¦æ˜¾ç¤º
6. **æµ‹è¯•éªŒè¯**: ç¡®ä¿åŠŸèƒ½æ­£å¸¸å·¥ä½œ

## âš ï¸ **æ³¨æ„äº‹é¡¹**

1. **APIè´¹ç”¨**: fal.ai æŒ‰ä½¿ç”¨é‡è®¡è´¹ï¼Œéœ€è¦ç›‘æ§æˆæœ¬
2. **å¤„ç†æ—¶é—´**: è§†é¢‘ç”Ÿæˆéœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œéœ€è¦è‰¯å¥½çš„ç”¨æˆ·ä½“éªŒ
3. **é”™è¯¯å¤„ç†**: éœ€è¦å®Œå–„çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
4. **å­˜å‚¨ç®¡ç†**: ç”Ÿæˆçš„è§†é¢‘æ–‡ä»¶éœ€è¦åˆç†çš„å­˜å‚¨ç­–ç•¥

## ğŸ”— **ç›¸å…³èµ„æº**

- [fal.ai å®˜æ–¹æ–‡æ¡£](https://fal.ai/docs)
- [Remotion æ–‡æ¡£](https://remotion.dev/docs)
- [åŸå§‹é¡¹ç›®ä»“åº“](https://github.com/fal-ai-community/video-starter-kit)

---

**ğŸ“ æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**ğŸ“… åˆ›å»ºæ—¶é—´**: 2025-01-20  
**ğŸ¯ ç”¨é€”**: fal.ai é›†æˆå‚è€ƒå’Œæœªæ¥å¼€å‘æŒ‡å— 